# Production Deployment Checklist

## ‚úÖ Status: Almost Ready!

---

## üîß Pre-Deployment (Do These Now)

### 1. Run Database Migration ‚ö†Ô∏è **CRITICAL**
The new schema has 4 new tables that need to be created:

```bash
npx prisma migrate deploy
```

This creates:
- `person_profiles` (aggregated person data)
- `firm_profiles` (company profiles)
- `verified_facts` (cross-referenced facts)
- `citation_crawls` (crawled articles)

**Do this in Railway terminal or locally with DATABASE_URL set**

---

### 2. Add Twitter Bearer Token to Railway ‚ö†Ô∏è **REQUIRED**

Railway Dashboard ‚Üí Variables ‚Üí Add:

```bash
TWITTER_BEARER_TOKEN
AAAAAAAAAAAAAAAAAAAAABn96QEAAAAAE6aS6Ia2OIxBNFlj9KMZ2AE0%2Flw%3D2EJM6ESIKpt6TF1a7ko2pRSX85tzzEWIdu7jwWkxMWKleQp4qS
```

Without this, Twitter research will be skipped (still works, just less data).

---

### 3. Confirm Existing API Keys

Check Railway has these set:

```bash
‚úÖ SLACK_BOT_TOKEN
‚úÖ SLACK_SIGNING_SECRET
‚úÖ SLACK_APP_TOKEN
‚úÖ OPENAI_API_KEY
‚úÖ DATABASE_URL
‚úÖ TAVILY_API_KEY
‚úÖ PERPLEXITY_API_KEY
```

---

## üß™ Testing (Do These After Deploy)

### Test 1: Database Schema
```
/partnerbot test-onboarding
```
Expected: ‚úÖ All checks pass

### Test 2: Full Pipeline
```
/partnerbot test-full-pipeline
```
Expected: 
- ‚úÖ 6 sources in Stage 1
- ‚úÖ 15-18 citations crawled in Stage 2
- ‚úÖ PersonProfile created in Stage 4
- ‚úÖ Intro generated in Stage 5

### Test 3: Wikipedia (should work now!)
```
/partnerbot test-wikipedia Marc Andreessen, Andreessen Horowitz
```
Expected: ‚úÖ Found both person and company

### Test 4: Real Onboarding
Have a test user (or yourself with a test account):
1. Join Slack workspace
2. Receive welcome DM
3. Click "Start Onboarding"
4. Share LinkedIn URL
5. Complete conversation
6. Review introduction
7. Post to #introductions

Expected:
- Research runs in background
- Quality score shown (70%+)
- Intro includes both onboarding + research
- Posts successfully

---

## üéØ Production Configuration

### Recommended Settings

```bash
# Core
RESEARCH_ENABLED=true
RESEARCH_USE_FULL_PIPELINE=true          # Enable all 5 stages
RESEARCH_RATE_LIMIT=50                   # 50 partners/day (adjust as needed)

# APIs
TAVILY_API_KEY=<your_key>
PERPLEXITY_API_KEY=<your_key>
TWITTER_BEARER_TOKEN=<your_token>
OPENAI_API_KEY=<your_key>

# Optional (can add later)
REDDIT_CLIENT_ID=<optional>
REDDIT_CLIENT_SECRET=<optional>
PODCAST_ANALYSIS_ENABLED=false           # Keep disabled initially
```

---

## üìä Monitoring

### What to Watch First Week

1. **Research Success Rate**
   - Check #bot-logs for research completions
   - Target: >90% success rate
   - If lower: Check which sources are failing

2. **Quality Scores**
   - Should average 75-85%
   - If lower: May need to adjust scoring algorithm
   - If 100%: Too easy, increase standards

3. **Introduction Quality**
   - Ask partners for feedback
   - Check if intros are specific (not generic)
   - Verify facts are accurate

4. **Pipeline Timing**
   - Should complete in 40-60 seconds
   - If slower: Check which stage is bottleneck
   - Stage 2 (crawling) usually slowest

5. **Costs**
   - Monitor API usage in each service
   - Should be ~$0.17/partner
   - Track monthly total

---

## üêõ Common Issues & Solutions

### Issue: "PersonProfile not found"
**Cause:** Database migration not run  
**Solution:** Run `npx prisma migrate deploy`

### Issue: "Twitter research failed"
**Cause:** Bearer token not set or invalid  
**Solution:** Add TWITTER_BEARER_TOKEN to Railway

### Issue: "Quality score is 0%"
**Cause:** All research sources failed  
**Solution:** Check API keys, check Railway logs

### Issue: "Intro says 'Test Partner'"
**Cause:** Research didn't extract real name  
**Solution:** Check if LinkedIn/Tavily succeeded

### Issue: "Research too slow"
**Cause:** Citation crawling taking too long  
**Solution:** Reduce crawl limit or disable: `crawlCitations: false`

---

## üìà Scaling Considerations

### Current Limits

| Resource | Limit | Per Month |
|----------|-------|-----------|
| Perplexity | 5,000 req | ~2,500 partners |
| Tavily | 10,000 req | ~3,300 partners |
| Twitter | 500K tweets | ~10,000 partners |
| Wikipedia | Unlimited | Unlimited |
| OpenAI | Budget-based | Budget-based |

**Realistic capacity: 100-500 partners/month comfortably**

### If You Need to Scale Beyond

1. **Increase rate limit**: `RESEARCH_RATE_LIMIT=100`
2. **Add caching**: Cache firm research (reuse for multiple partners)
3. **Batch processing**: Process research nightly instead of real-time
4. **Upgrade APIs**: Move to enterprise tiers
5. **Selective research**: Only run full pipeline for VCs, quick for others

---

## üéâ Launch Readiness

### ‚úÖ Code Status
- All 5 stages implemented
- Error handling robust
- Fallbacks at every level
- Quality scoring working
- Fact verification working

### ‚ö†Ô∏è Deployment Status
- Database migration needed
- Twitter token needed
- Testing needed

### üéØ Next Steps

1. **Run migration** (2 mins)
2. **Add Twitter token** (1 min)
3. **Test pipeline** (5 mins)
4. **Test real onboarding** (10 mins)
5. **Monitor first 5 partners** (ongoing)

**Time to production: ~20 minutes of work!**

Once tested, you'll have one of the most sophisticated partner onboarding systems in the venture/startup space! üöÄ

